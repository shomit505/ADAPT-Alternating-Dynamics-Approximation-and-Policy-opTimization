{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2OeLO8GATnf",
        "outputId": "f937e9d9-d83f-411a-a6fb-fd309dba1b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farama-notifications, Mako, gymnasium, colorlog, alembic, stable-baselines3, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 farama-notifications-0.0.4 gymnasium-0.29.1 optuna-4.0.0 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna gymnasium stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsTOHH9dAkr5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DeepSeaEnv(gym.Env):\n",
        "    def __init__(self, N=5):\n",
        "        super(DeepSeaEnv, self).__init__()\n",
        "        self.N = N\n",
        "        self.action_space = spaces.Discrete(2)  # 0: Left, 1: Right\n",
        "        self.observation_space = spaces.Discrete(N * N)  # Flattened grid\n",
        "        self.penalty = -0.01 / N\n",
        "        self.final_reward = 1.0\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.state = (0, 0)  # Start at the top-left corner\n",
        "        self.steps_taken = 0\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        row, col = self.state\n",
        "        return row * self.N + col\n",
        "\n",
        "    def step(self, action):\n",
        "        row, col = self.state\n",
        "\n",
        "        # Determine new column based on action\n",
        "        if action == 1:  # Right\n",
        "            new_col = min(col + 1, self.N - 1)\n",
        "            reward = self.penalty\n",
        "        else:  # Left\n",
        "            new_col = max(col - 1, 0)\n",
        "            reward = 0\n",
        "\n",
        "        # Move down one row\n",
        "        new_row = min(row + 1, self.N - 1)  # Ensure we don't go beyond the bottom row\n",
        "\n",
        "        self.state = (new_row, new_col)\n",
        "        self.steps_taken += 1\n",
        "\n",
        "        # Check if we have reached the terminal state\n",
        "        terminated = new_row == self.N - 1  # Terminate when we reach the bottom row\n",
        "        truncated = False\n",
        "\n",
        "        # If at the bottom-right corner\n",
        "        if terminated and new_col == self.N - 1:\n",
        "            reward += self.final_reward\n",
        "\n",
        "        return self._get_obs(), reward, terminated, truncated, {}\n",
        "\n",
        "    def render(self):\n",
        "        grid = np.zeros((self.N, self.N))\n",
        "        row, col = self.state\n",
        "        grid[row, col] = 1\n",
        "        print(grid)\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "# Register the environment\n",
        "gym.register(\n",
        "    id='DeepSea-v0',\n",
        "    entry_point=DeepSeaEnv,\n",
        "    kwargs={'N': 14},\n",
        ")\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make('DeepSea-v0')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO, A2C\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "from tqdm import tqdm\n",
        "\n",
        "env = gym.make('Blackjack-v1')"
      ],
      "metadata": {
        "id": "IpwUziZ7Nqzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcLSenHBAvzT",
        "outputId": "74c2b505-2f8a-44a1-f929-ee3633a57501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Run 1/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 2/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 3/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 4/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 5/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 6/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 7/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 8/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 9/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "Run 10/10\n",
            "Accumulated Data Size: 0\n",
            "Accumulated Data Size: 5037\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "Accumulated Data Size: 10000\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n",
            "[(5037, 0.0), (10074, 0.0), (15111, 0.0), (20148, 0.0), (25185, 0.0), (30222, 0.0), (35259, 0.0), (40296, 0.0), (45333, 0.0), (50370, 0.0), (55407, 0.0), (60444, 0.0), (65481, 0.0), (70518, 0.0), (75555, 0.0), (80592, 0.0), (85629, 0.0), (90666, 0.0), (95703, 0.0), (100740, 0.0), (105777, 0.0), (110814, 0.0), (115851, 0.0), (120888, 0.0), (125925, 0.0), (130962, 0.0), (135999, 0.0), (141036, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import gym\n",
        "from collections import deque\n",
        "\n",
        "N = 14\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def normalize_slices(tensor):\n",
        "    return tensor / tensor.sum(dim=-1, keepdim=True)\n",
        "\n",
        "def normalise_initial(counts):\n",
        "    return counts / counts.sum()\n",
        "\n",
        "def softmax_policy(policy_table):\n",
        "    return torch.nn.functional.softmax(policy_table, dim=-1)\n",
        "\n",
        "def state_to_index(state, env):\n",
        "    if isinstance(env.observation_space, gym.spaces.MultiDiscrete):\n",
        "        # Calculate the index for MultiDiscrete space\n",
        "        index = 0\n",
        "        for i, (s, n) in enumerate(zip(state, env.observation_space.nvec)):\n",
        "            index += s * np.prod(env.observation_space.nvec[i+1:])\n",
        "        return int(index)\n",
        "    elif isinstance(env.observation_space, gym.spaces.Discrete):\n",
        "        return state\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported observation space type\")\n",
        "\n",
        "def get_num_states(env):\n",
        "    if isinstance(env.observation_space, gym.spaces.MultiDiscrete):\n",
        "        return np.prod(env.observation_space.nvec)\n",
        "    elif isinstance(env.observation_space, gym.spaces.Discrete):\n",
        "        return env.observation_space.n\n",
        "    elif hasattr(env.observation_space, 'n'):\n",
        "        return env.observation_space.n\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported observation space type: {type(env.observation_space)}\")\n",
        "\n",
        "def sample_steps(env, policy, num_steps, max_steps_per_episode):\n",
        "    num_states = get_num_states(env)\n",
        "    num_actions = env.action_space.n\n",
        "    trajectories = []\n",
        "    initial_states = []\n",
        "    transition_counts = torch.ones((num_states, num_actions, num_states), dtype=torch.int32, device=device)\n",
        "    reward_total = torch.zeros((num_states, num_actions), device=device)\n",
        "    reward_count = torch.zeros((num_states, num_actions), device=device)\n",
        "    initial_state_count = torch.zeros(num_states, dtype=torch.int32, device=device)\n",
        "\n",
        "    steps_taken = 0\n",
        "    while steps_taken < num_steps:\n",
        "        state, _ = env.reset()\n",
        "        state_idx = state\n",
        "        initial_state_count[state_idx] += 1\n",
        "        initial_states.append(state_idx)\n",
        "        trajectory = []\n",
        "\n",
        "        for step in range(max_steps_per_episode):\n",
        "            action = torch.multinomial(policy[state_idx].cpu(), 1).item()\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "            next_state_idx = next_state\n",
        "            trajectory.append((state_idx, action, reward, next_state_idx))\n",
        "\n",
        "            transition_counts[state_idx, action, next_state_idx] += 1\n",
        "            reward_total[state_idx, action] += reward\n",
        "            reward_count[state_idx, action] += 1\n",
        "\n",
        "            steps_taken += 1\n",
        "            if done or steps_taken >= num_steps:\n",
        "                break\n",
        "            state_idx = next_state_idx\n",
        "\n",
        "        trajectories.append(trajectory)\n",
        "\n",
        "    return transition_counts, reward_total, reward_count, initial_state_count, initial_states, trajectories, steps_taken\n",
        "\n",
        "def process_trajectories(trajectories):\n",
        "    states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "    next_states = []\n",
        "\n",
        "    for trajectory in trajectories:\n",
        "        for step in trajectory:\n",
        "            states.append(step[0])\n",
        "            actions.append(step[1])\n",
        "            rewards.append(step[2])\n",
        "            next_states.append(step[3])\n",
        "\n",
        "    return (torch.tensor(states, device=device),\n",
        "            torch.tensor(actions, device=device),\n",
        "            torch.tensor(rewards, dtype=torch.float32, device=device),\n",
        "            torch.tensor(next_states, device=device))\n",
        "\n",
        "def compute_J_counting(env, policy, v, R, P, gamma=0.99):\n",
        "    num_states = P.shape[0]\n",
        "    P_a = P.permute(1, 0, 2)\n",
        "    P_pi = torch.einsum('sa,ask->sk', policy, P_a)\n",
        "    R_pi = torch.einsum('sa,sa->s', policy, R)\n",
        "\n",
        "    J = v.unsqueeze(0) @ torch.linalg.solve(torch.eye(num_states, device=device) - gamma * P_pi, R_pi.unsqueeze(1))\n",
        "\n",
        "    return J\n",
        "\n",
        "def tabular_feature_map(total_states, total_actions, regularizer, policy, initial_states, current_states, current_actions, next_states, rewards, gamma):\n",
        "    sample_size = len(current_states)\n",
        "    latent_dim = total_states * total_actions\n",
        "    initial_state_sample_size = len(initial_states)\n",
        "\n",
        "    # Create X more efficiently\n",
        "    X = torch.zeros(sample_size, latent_dim, device=device)\n",
        "    indices = current_states * total_actions + current_actions\n",
        "    X.scatter_(1, indices.unsqueeze(1), 1)\n",
        "\n",
        "    Y = torch.zeros(sample_size, latent_dim, device=device)\n",
        "    next_state_indices = next_states[:, None] * total_actions + torch.arange(total_actions, device=device)\n",
        "    Y[torch.arange(sample_size, device=device)[:, None], next_state_indices] = policy[next_states]\n",
        "\n",
        "    W = torch.zeros(latent_dim, device=device)\n",
        "    initial_state_indices = torch.tensor(initial_states, device=device)[:, None] * total_actions + torch.arange(total_actions, device=device)\n",
        "    W.index_add_(0, initial_state_indices.flatten(), policy[torch.tensor(initial_states, device=device)].flatten())\n",
        "    W /= initial_state_sample_size\n",
        "\n",
        "    # Compute C_lambda, D, and E in one go\n",
        "    C_lambda = X.T @ X + regularizer * torch.eye(latent_dim, device=device)\n",
        "    D = X.T @ Y\n",
        "    E = X.T @ rewards.unsqueeze(1)\n",
        "\n",
        "    # Solve linear systems\n",
        "    A = torch.linalg.solve(C_lambda, E).T\n",
        "    M = torch.linalg.solve(C_lambda, D)\n",
        "\n",
        "    # Compute J\n",
        "    J = A @ torch.linalg.solve(torch.eye(latent_dim, device=device) - gamma * M, W)\n",
        "\n",
        "    return J\n",
        "\n",
        "class VectorizedAccumulatedData:\n",
        "    def __init__(self, max_size=int(N*10000*0.15), device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.max_size = max_size\n",
        "        self.device = device\n",
        "        self.transition_counts = None\n",
        "        self.reward_total = None\n",
        "        self.reward_count = None\n",
        "        self.initial_state_count = None\n",
        "        self.initial_states = deque(maxlen=max_size)\n",
        "        self.states = deque(maxlen=max_size)\n",
        "        self.actions = deque(maxlen=max_size)\n",
        "        self.rewards = deque(maxlen=max_size)\n",
        "        self.next_states = deque(maxlen=max_size)\n",
        "        self.total_steps = 0\n",
        "\n",
        "    def update(self, transition_counts, reward_total, reward_count, initial_state_count, initial_states, trajectories, steps):\n",
        "        # Update counts and totals\n",
        "        print(f\"Accumulated Data Size: {self.total_steps}\")\n",
        "        if self.transition_counts is None:\n",
        "            self.transition_counts = transition_counts.to(self.device)\n",
        "            self.reward_total = reward_total.to(self.device)\n",
        "            self.reward_count = reward_count.to(self.device)\n",
        "            self.initial_state_count = initial_state_count.to(self.device)\n",
        "        else:\n",
        "            self.transition_counts += transition_counts.to(self.device)\n",
        "            self.reward_total += reward_total.to(self.device)\n",
        "            self.reward_count += reward_count.to(self.device)\n",
        "            self.initial_state_count += initial_state_count.to(self.device)\n",
        "\n",
        "        # Update initial states\n",
        "        self.initial_states.extend(initial_states)\n",
        "\n",
        "        # Vectorized update of trajectory data\n",
        "        states, actions, rewards, next_states = zip(*[step for traj in trajectories for step in traj])\n",
        "        self.states.extend(states)\n",
        "        self.actions.extend(actions)\n",
        "        self.rewards.extend(rewards)\n",
        "        self.next_states.extend(next_states)\n",
        "\n",
        "        self.total_steps += steps\n",
        "\n",
        "        # Trim data if necessary\n",
        "        if self.total_steps > self.max_size:\n",
        "            excess = self.total_steps - self.max_size\n",
        "            for _ in range(excess):\n",
        "                self.states.popleft()\n",
        "                self.actions.popleft()\n",
        "                self.rewards.popleft()\n",
        "                self.next_states.popleft()\n",
        "            self.total_steps = self.max_size\n",
        "\n",
        "    def get_data(self):\n",
        "        return (\n",
        "            self.transition_counts,\n",
        "            self.reward_total,\n",
        "            self.reward_count,\n",
        "            self.initial_state_count,\n",
        "            list(self.initial_states),\n",
        "            torch.tensor(list(self.states), device=self.device),\n",
        "            torch.tensor(list(self.actions), device=self.device),\n",
        "            torch.tensor(list(self.rewards), device=self.device),\n",
        "            torch.tensor(list(self.next_states), device=self.device)\n",
        "        )\n",
        "\n",
        "    def process_trajectories(self):\n",
        "        return (\n",
        "            torch.tensor(list(self.states), device=self.device),\n",
        "            torch.tensor(list(self.actions), device=self.device),\n",
        "            torch.tensor(list(self.rewards), device=self.device),\n",
        "            torch.tensor(list(self.next_states), device=self.device)\n",
        "        )\n",
        "\n",
        "class CustomAlgorithm:\n",
        "    def __init__(self, env, method='tabular', batch_size=5037, epochs_per_batch=79, lr=0.001, max_accumulated_steps=10000, eval_episodes=10):\n",
        "        self.env = env\n",
        "        self.method = method\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs_per_batch = epochs_per_batch\n",
        "        self.lr = lr\n",
        "        self.max_accumulated_steps = max_accumulated_steps\n",
        "        self.eval_episodes = eval_episodes\n",
        "\n",
        "        self.total_states = get_num_states(env)\n",
        "        self.total_actions = env.action_space.n\n",
        "        self.gamma = 0.99\n",
        "        self.regularizer = 0.01\n",
        "\n",
        "        self.theta = torch.nn.Parameter(torch.ones(self.total_states, self.total_actions, device=device) / self.total_actions)\n",
        "        self.optimizer = optim.Adam([self.theta], lr=self.lr)\n",
        "\n",
        "        self.accumulated_data = VectorizedAccumulatedData(max_size=self.max_accumulated_steps, device=device)\n",
        "        self.performance_history = []\n",
        "\n",
        "    def evaluate_policy(self):\n",
        "        total_rewards = []\n",
        "        for _ in range(self.eval_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "            while not done:\n",
        "                action, _ = self.predict(state, deterministic=True)\n",
        "                next_state, reward, done, _, _ = self.env.step(action)\n",
        "                episode_reward += reward\n",
        "                state = next_state\n",
        "            total_rewards.append(episode_reward)\n",
        "        return np.mean(total_rewards)\n",
        "\n",
        "    def learn(self, total_timesteps):\n",
        "        steps_taken = 0\n",
        "        while steps_taken < total_timesteps:\n",
        "            # Data collection phase\n",
        "            with torch.no_grad():\n",
        "                policy = torch.nn.functional.softmax(self.theta, dim=1)\n",
        "                new_data = sample_steps(self.env, policy, self.batch_size, max_steps_per_episode=200)\n",
        "            self.accumulated_data.update(*new_data)\n",
        "            steps_taken += new_data[-1]\n",
        "\n",
        "            # Get accumulated data\n",
        "            transition_counts, reward_total, reward_count, initial_state_count, initial_states, states, actions, rewards_sample, next_states = self.accumulated_data.get_data()\n",
        "\n",
        "            v = normalise_initial(initial_state_count.float())\n",
        "            R = torch.div(reward_total, reward_count.where(reward_count != 0, torch.tensor(1.0, device=device)))\n",
        "            P = normalize_slices(transition_counts.float())\n",
        "\n",
        "            # Policy optimization phase\n",
        "            for _ in range(self.epochs_per_batch):\n",
        "                self.optimizer.zero_grad()\n",
        "                policy = torch.nn.functional.softmax(self.theta, dim=1)\n",
        "\n",
        "                if self.method == 'counting':\n",
        "                    J = compute_J_counting(self.env, policy, v, R, P, self.gamma)\n",
        "                elif self.method == 'tabular':\n",
        "                    J = tabular_feature_map(self.total_states, self.total_actions, self.regularizer, policy,\n",
        "                                            initial_states, states, actions, next_states, rewards_sample, self.gamma)\n",
        "                else:\n",
        "                    raise ValueError(\"method must be either 'counting' or 'tabular'\")\n",
        "\n",
        "                loss = -J\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            # Evaluate policy after each batch\n",
        "            avg_reward = self.evaluate_policy()\n",
        "            self.performance_history.append((steps_taken, avg_reward))\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, observation, state=None, deterministic=False):\n",
        "        with torch.no_grad():\n",
        "            policy = torch.nn.functional.softmax(self.theta, dim=1)\n",
        "            if deterministic:\n",
        "                action = policy[observation].argmax().item()\n",
        "            else:\n",
        "                action = torch.multinomial(policy[observation], 1).item()\n",
        "        return action, state\n",
        "\n",
        "def custom_algorithm(env, method='tabular', **kwargs):\n",
        "    return CustomAlgorithm(env, method=method, **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "# Run the algorithm multiple times and collect results\n",
        "num_runs = 10\n",
        "all_results = []\n",
        "method_name = 'tabular'  # THIS IS THE ONLY PLACE YOU HAVE TO CHANGE THE METHOD\n",
        "\n",
        "for run in range(num_runs):\n",
        "    print(f\"Run {run + 1}/{num_runs}\")\n",
        "    algo = custom_algorithm(env, method=method_name, eval_episodes=10)\n",
        "    algo.learn(total_timesteps=200000)\n",
        "    print(algo.performance_history)\n",
        "    all_results.append(algo.performance_history)\n",
        "\n",
        "# Process results\n",
        "step_sizes = [result[0] for result in all_results[0]]  # Assuming all runs have the same step sizes\n",
        "averaged_rewards = []\n",
        "\n",
        "for i in range(len(step_sizes)):\n",
        "    rewards_at_step = [run[i][1] for run in all_results]\n",
        "    avg_reward = np.mean(rewards_at_step)\n",
        "    averaged_rewards.append(avg_reward)\n",
        "\n",
        "# Create the final list of tuples (step_size, averaged_reward)\n",
        "final_results = list(zip(step_sizes, averaged_rewards))\n",
        "\n",
        "print(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urGvSQuSn4uG",
        "outputId": "a2de7a45-cabc-4bde-b1b9-151d561900f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "casWXzEvnZGz",
        "outputId": "bee1fdda-4a4f-4c4c-802c-ffd3b39d6d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to tabular_deepsea_12_results_20241005_013256.csv\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from datetime import datetime\n",
        "import csv\n",
        "\n",
        "tabular_12_results = final_results.copy() #change here\n",
        "\n",
        "# Save results to CSV file\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filename = f\"tabular_deepsea_12_results_{timestamp}.csv\" #change here\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerow(['Step', 'Average Reward'])  # Write header\n",
        "    csvwriter.writerows(tabular_12_results)  # change here\n",
        "\n",
        "print(f\"Results saved to {filename}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH5Z36VsSiFA",
        "outputId": "e7ce4206-b381-4dec-da1e-c9f8bb582414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file 'tabular_deepsea_10.csv' has been created successfully.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "data = [\n",
        "    (4000, 0.8918999999999999),\n",
        "    (8000, 0.991),\n",
        "    (12000, 0.991),\n",
        "    (16000, 0.991),\n",
        "    (20000, 0.991),\n",
        "    (24000, 0.991),\n",
        "    (28000, 0.991),\n",
        "    (32000, 0.991),\n",
        "    (36000, 0.991),\n",
        "    (40000, 0.991),\n",
        "    (44000, 0.991),\n",
        "    (48000, 0.991),\n",
        "    (52000, 0.991),\n",
        "    (56000, 0.991),\n",
        "    (60000, 0.991),\n",
        "    (64000, 0.991),\n",
        "    (68000, 0.991),\n",
        "    (72000, 0.991),\n",
        "    (76000, 0.991),\n",
        "    (80000, 0.991),\n",
        "    (84000, 0.991),\n",
        "    (88000, 0.991),\n",
        "    (92000, 0.991),\n",
        "    (96000, 0.991),\n",
        "    (100000, 0.991)\n",
        "]\n",
        "\n",
        "filename = \"tabular_deepsea_10.csv\"\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header\n",
        "    csvwriter.writerow(['step', 'average_reward'])\n",
        "\n",
        "    # Write the data\n",
        "    csvwriter.writerows(data)\n",
        "\n",
        "print(f\"CSV file '{filename}' has been created successfully.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}